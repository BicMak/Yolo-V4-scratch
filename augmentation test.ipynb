{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "\n",
    "import Custom_dataset\n",
    "import anchor\n",
    "import backbone\n",
    "from CustomAugment import Cutmix\n",
    "from configuration import dataset_config\n",
    "from configuration import dataloader_config\n",
    "from configuration import OptimizerConfig\n",
    "from configuration import augmentation_config\n",
    "from configuration import training_config\n",
    "from loss import DetectionLoss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set size: 1084, test_set size : 272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.train()\\nfor epoch in range(training_config.epochs):\\n    for i, data in enumerate(train_dataloader):\\n        print(f\"batch shape: {data[\\'image\\'].shape}\")\\n        print(f\"bboxes shape: {data[\\'bboxes\\'].shape}\")\\n        print(f\"class_labels shape: {data[\\'class_labels\\'].shape}\")\\n        print(f\"image shape: {data[\\'image\\'].shape}\")\\n        print(\"\\n\")\\n        gt_datas = data\\n        output = model(data[\\'image\\'])\\n        break\\n    break\\n\\n\\n\\n\\nfor i, data in enumerate(train_dataset):\\n    print(f\"\\nüåÄ step : {i}\")\\n    print(f\"bboxes shape: {data[\\'bboxes\\'].shape}\")\\n    print(f\"class_labels shape: {data[\\'class_labels\\'].shape}\")\\n    \\n    result_bboxes, result_labels = image_test.encoder.encoder(data[\\'bboxes\\'], data[\\'class_labels\\'])\\n    \\n    print(f\"result_bboxes shape: {result_bboxes.shape}\")\\n    print(f\"result_labels shape: {result_labels.shape}\")\\n    if i == 5:\\n        break\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "image_dir = dataset_config.image_dir\n",
    "label_dir = dataset_config.label_dir\n",
    "classes = dataset_config.classes\n",
    "img_size = dataset_config.image_size\n",
    "\n",
    "image_test =Custom_dataset.ListDataset(image_dir,\n",
    "                                       label_dir,\n",
    "                                       classes,\n",
    "                                       transform=augmentation_config.transform)\n",
    "\n",
    "# RabdinSized BBox Safe Crop has box bigger than 1% of image size\n",
    "train_transform = A.Compose([\n",
    "    A.RandomSizedBBoxSafeCrop(width=img_size,height=img_size,erosion_rate=0.8),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'], # Specify label argument name(s)\n",
    "                            ))\n",
    "\n",
    "final_transform = A.Compose([\n",
    "    A.AdditiveNoise(noise_type=\"gaussian\",\n",
    "                    spatial_mode=\"constant\",\n",
    "                    noise_params={\"mean_range\": (0.0, 0.0), \"std_range\": (0.05, 0.15)}),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),\n",
    "    A.Affine(translate_percent={'x': (-0.2, 0.2), 'y': (-0.2, 0.2)},  # xÏ∂ï 10~20%, yÏ∂ï -20~20% ÎûúÎç§ Ïù¥Îèô\n",
    "             p=0.3),\n",
    "    A.Affine(rotate = (-20,20), p = 0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'], # Specify label argument name(s)\n",
    "                           ))\n",
    "\n",
    "aug_para ={\"alpha\":augmentation_config.alpha,\n",
    "           \"lambda\":augmentation_config.lamda,\n",
    "           \"prob\":augmentation_config.prob}\n",
    "\n",
    "\n",
    "image_test.add_agumentation(train_transform,aug_para,final_transform)\n",
    "\n",
    "set_size = len(image_test)\n",
    "train_dataset_size = int(0.8*set_size)\n",
    "test_dataset_size = set_size-train_dataset_size\n",
    "\n",
    "train_indces, valid_indces = torch.utils.data.random_split(range(set_size), [train_dataset_size, test_dataset_size])\n",
    "print(\"set size: {0}, test_set size : {1}\".format(train_dataset_size,test_dataset_size))\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(image_test, train_indces)\n",
    "valid_dataset = torch.utils.data.Subset(image_test, train_indces)\n",
    "# This problem is occured in Dater type interupt between array and tensor\n",
    "\n",
    "batch_size = dataloader_config.batch_size\n",
    "num_workers = dataloader_config.num_workers\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=dataloader_config.batch_size,\n",
    "                                               num_workers=dataloader_config.num_workers,\n",
    "                                               shuffle = dataloader_config.shuffle,\n",
    "                                               collate_fn = image_test.collate_fn)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=dataloader_config.batch_size,\n",
    "                                               num_workers=dataloader_config.num_workers,\n",
    "                                               collate_fn = image_test.collate_fn)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "model = backbone.YoloV4Model(num_classes=len(dataset_config.classes),\n",
    "                             to_vector = True)\n",
    "\n",
    "'''\n",
    "model.train()\n",
    "for epoch in range(training_config.epochs):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        print(f\"batch shape: {data['image'].shape}\")\n",
    "        print(f\"bboxes shape: {data['bboxes'].shape}\")\n",
    "        print(f\"class_labels shape: {data['class_labels'].shape}\")\n",
    "        print(f\"image shape: {data['image'].shape}\")\n",
    "        print(\"\\n\")\n",
    "        gt_datas = data\n",
    "        output = model(data['image'])\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    print(f\"\\nüåÄ step : {i}\")\n",
    "    print(f\"bboxes shape: {data['bboxes'].shape}\")\n",
    "    print(f\"class_labels shape: {data['class_labels'].shape}\")\n",
    "    \n",
    "    result_bboxes, result_labels = image_test.encoder.encoder(data['bboxes'], data['class_labels'])\n",
    "    \n",
    "    print(f\"result_bboxes shape: {result_bboxes.shape}\")\n",
    "    print(f\"result_labels shape: {result_labels.shape}\")\n",
    "    if i == 5:\n",
    "        break\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(output[0].shape)\\nprint(output[1].shape)\\nprint(output[2].shape)\\n\\nprint(result.shape)\\n#ÎÇ¥Ïùº ÏïÑÏπ®Ïóê ÏùºÏñ¥ÎÇòÏÑú ÌôïÏù∏Ìï¥Î¥êÏïºÎê†Í±∞ -> result ÌÖêÏÑúÌÅ¨Í∏∞ ÌôïÏù∏Ïù∏\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(output[0].shape)\n",
    "print(output[1].shape)\n",
    "print(output[2].shape)\n",
    "\n",
    "print(result.shape)\n",
    "#ÎÇ¥Ïùº ÏïÑÏπ®Ïóê ÏùºÏñ¥ÎÇòÏÑú ÌôïÏù∏Ìï¥Î¥êÏïºÎê†Í±∞ -> result ÌÖêÏÑúÌÅ¨Í∏∞ ÌôïÏù∏Ïù∏\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define total batch size \n",
    "total_batch_size = math.ceil(train_dataset_size / dataloader_config.batch_size)  # total batch size for all GPUs, accumulate, and gradient steps\n",
    "\n",
    "nbs = 64  # nominal batch size\n",
    "accumulate = max(round(nbs / total_batch_size), 1)  # accumulate loss before optimizing\n",
    "modified_weight_decay= OptimizerConfig.weight_decay * total_batch_size * accumulate / nbs  # scale weight_decay\n",
    "optimizer = optim.Adam(params = model.parameters(),\n",
    "                       lr=OptimizerConfig.lr0, \n",
    "                       weight_decay=modified_weight_decay, #L2 regularization\n",
    "                       betas=(0.9,0.999) )  # adjust beta1 to momentum\n",
    "\n",
    "\n",
    "# Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
    "# https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR\n",
    "warmup_end_lr =  (1-OptimizerConfig.lrf)/2+OptimizerConfig.lrf  # warmup end learning rate\n",
    "warmup_scheduler = lr_scheduler.LinearLR(optimizer, \n",
    "                                         start_factor=OptimizerConfig.lr0, \n",
    "                                         end_factor= warmup_end_lr,\n",
    "                                         total_iters=training_config.warmup_epochs)\n",
    "\n",
    "# Cosine decay after warmup\n",
    "epochs_cosine = training_config.epochs - training_config.warmup_epochs\n",
    "lf = lambda x: ((1 + math.cos(x * math.pi / epochs_cosine)) / 2) * (1 - OptimizerConfig.lrf) + OptimizerConfig.lrf  # cosine\n",
    "cosine_scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "yolo_scheduler = lr_scheduler.SequentialLR(optimizer,\n",
    "                                           schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "                                           milestones=[training_config.warmup_epochs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import DetectionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\npred_loc = result[:,:,:4]\\npred_obj = result[:,:,4]\\nprod_cls = result[:,:,5:]\\n\\n\\ngt_bboxes = gt_datas[\\'bboxes\\']\\ngt_class_labels = gt_datas[\\'class_labels\\']\\ngt_class_labels = gt_class_labels.view(gt_class_labels.shape[0],\\n                                       gt_class_labels.shape[1],\\n                                       1)\\ngt = torch.cat((gt_bboxes,gt_class_labels),dim=2)\\nprint(f\"gt shape: {gt.shape}\")\\nprint(f\"result shape: {result.shape}\")\\n\\n\\nloss_value = loss.forward(result, gt)\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "pred_loc = result[:,:,:4]\n",
    "pred_obj = result[:,:,4]\n",
    "prod_cls = result[:,:,5:]\n",
    "\n",
    "\n",
    "gt_bboxes = gt_datas['bboxes']\n",
    "gt_class_labels = gt_datas['class_labels']\n",
    "gt_class_labels = gt_class_labels.view(gt_class_labels.shape[0],\n",
    "                                       gt_class_labels.shape[1],\n",
    "                                       1)\n",
    "gt = torch.cat((gt_bboxes,gt_class_labels),dim=2)\n",
    "print(f\"gt shape: {gt.shape}\")\n",
    "print(f\"result shape: {result.shape}\")\n",
    "\n",
    "\n",
    "loss_value = loss.forward(result, gt)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning rate: 0.01\n",
      "[0/100] training start\n",
      "loss value: {'total': tensor(0.7084, grad_fn=<AddBackward0>), 'ciou': tensor(3.5572, grad_fn=<MeanBackward0>), 'obj': tensor(0.0509, grad_fn=<MeanBackward0>), 'cls': tensor(0.6540, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.8432, grad_fn=<AddBackward0>), 'ciou': tensor(5.2461, grad_fn=<MeanBackward0>), 'obj': tensor(0.0659, grad_fn=<MeanBackward0>), 'cls': tensor(0.6347, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.7861, grad_fn=<AddBackward0>), 'ciou': tensor(4.9092, grad_fn=<MeanBackward0>), 'obj': tensor(0.0553, grad_fn=<MeanBackward0>), 'cls': tensor(0.6392, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.0019000000000000004\n",
      "[1/100] training start\n",
      "loss value: {'total': tensor(0.7520, grad_fn=<AddBackward0>), 'ciou': tensor(3.5711, grad_fn=<MeanBackward0>), 'obj': tensor(0.0655, grad_fn=<MeanBackward0>), 'cls': tensor(0.6233, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(24.6785, grad_fn=<AddBackward0>), 'ciou': tensor(481.9922, grad_fn=<MeanBackward0>), 'obj': tensor(0.0787, grad_fn=<MeanBackward0>), 'cls': tensor(0.5281, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.8522, grad_fn=<AddBackward0>), 'ciou': tensor(5.3892, grad_fn=<MeanBackward0>), 'obj': tensor(0.0870, grad_fn=<MeanBackward0>), 'cls': tensor(0.4696, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.0037000000000000006\n",
      "[2/100] training start\n",
      "loss value: {'total': tensor(0.6462, grad_fn=<AddBackward0>), 'ciou': tensor(3.9022, grad_fn=<MeanBackward0>), 'obj': tensor(0.0566, grad_fn=<MeanBackward0>), 'cls': tensor(0.4494, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(10.8475, grad_fn=<AddBackward0>), 'ciou': tensor(209.8291, grad_fn=<MeanBackward0>), 'obj': tensor(0.0379, grad_fn=<MeanBackward0>), 'cls': tensor(0.4087, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(13.7149, grad_fn=<AddBackward0>), 'ciou': tensor(267.0183, grad_fn=<MeanBackward0>), 'obj': tensor(0.0466, grad_fn=<MeanBackward0>), 'cls': tensor(0.3554, grad_fn=<MeanBackward0>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "[3/100] training start\n",
      "loss value: {'total': tensor(7.5341, grad_fn=<AddBackward0>), 'ciou': tensor(145.0496, grad_fn=<MeanBackward0>), 'obj': tensor(0.0309, grad_fn=<MeanBackward0>), 'cls': tensor(0.3163, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(100.0504, grad_fn=<AddBackward0>), 'ciou': tensor(1997.2458, grad_fn=<MeanBackward0>), 'obj': tensor(0.0134, grad_fn=<MeanBackward0>), 'cls': tensor(0.2692, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.3401, grad_fn=<AddBackward0>), 'ciou': tensor(3.1530, grad_fn=<MeanBackward0>), 'obj': tensor(0.0106, grad_fn=<MeanBackward0>), 'cls': tensor(0.2801, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009997640060704818\n",
      "[4/100] training start\n",
      "loss value: {'total': tensor(0.3434, grad_fn=<AddBackward0>), 'ciou': tensor(2.8521, grad_fn=<MeanBackward0>), 'obj': tensor(0.0146, grad_fn=<MeanBackward0>), 'cls': tensor(0.2846, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2847, grad_fn=<AddBackward0>), 'ciou': tensor(2.9412, grad_fn=<MeanBackward0>), 'obj': tensor(0.0066, grad_fn=<MeanBackward0>), 'cls': tensor(0.2229, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.5974, grad_fn=<AddBackward0>), 'ciou': tensor(9.7014, grad_fn=<MeanBackward0>), 'obj': tensor(0.0046, grad_fn=<MeanBackward0>), 'cls': tensor(0.1878, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009990562718069702\n",
      "[5/100] training start\n",
      "loss value: {'total': tensor(0.2726, grad_fn=<AddBackward0>), 'ciou': tensor(2.2095, grad_fn=<MeanBackward0>), 'obj': tensor(0.0058, grad_fn=<MeanBackward0>), 'cls': tensor(0.2777, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2680, grad_fn=<AddBackward0>), 'ciou': tensor(2.3900, grad_fn=<MeanBackward0>), 'obj': tensor(0.0045, grad_fn=<MeanBackward0>), 'cls': tensor(0.2611, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2039, grad_fn=<AddBackward0>), 'ciou': tensor(2.1598, grad_fn=<MeanBackward0>), 'obj': tensor(0.0012, grad_fn=<MeanBackward0>), 'cls': tensor(0.1822, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009978775395249762\n",
      "[6/100] training start\n",
      "loss value: {'total': tensor(0.3972, grad_fn=<AddBackward0>), 'ciou': tensor(5.5214, grad_fn=<MeanBackward0>), 'obj': tensor(0.0022, grad_fn=<MeanBackward0>), 'cls': tensor(0.2243, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.5860, grad_fn=<AddBackward0>), 'ciou': tensor(9.4798, grad_fn=<MeanBackward0>), 'obj': tensor(0.0014, grad_fn=<MeanBackward0>), 'cls': tensor(0.2125, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2203, grad_fn=<AddBackward0>), 'ciou': tensor(2.1135, grad_fn=<MeanBackward0>), 'obj': tensor(0.0020, grad_fn=<MeanBackward0>), 'cls': tensor(0.2136, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009962290455518913\n",
      "[7/100] training start\n",
      "loss value: {'total': tensor(0.2513, grad_fn=<AddBackward0>), 'ciou': tensor(2.0336, grad_fn=<MeanBackward0>), 'obj': tensor(0.0017, grad_fn=<MeanBackward0>), 'cls': tensor(0.2857, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2368, grad_fn=<AddBackward0>), 'ciou': tensor(2.0797, grad_fn=<MeanBackward0>), 'obj': tensor(0.0015, grad_fn=<MeanBackward0>), 'cls': tensor(0.2535, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.5463, grad_fn=<AddBackward0>), 'ciou': tensor(9.0761, grad_fn=<MeanBackward0>), 'obj': tensor(0.0006, grad_fn=<MeanBackward0>), 'cls': tensor(0.1798, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009941125189302508\n",
      "[8/100] training start\n",
      "loss value: {'total': tensor(0.1911, grad_fn=<AddBackward0>), 'ciou': tensor(1.9729, grad_fn=<MeanBackward0>), 'obj': tensor(0.0008, grad_fn=<MeanBackward0>), 'cls': tensor(0.1788, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2228, grad_fn=<AddBackward0>), 'ciou': tensor(2.0936, grad_fn=<MeanBackward0>), 'obj': tensor(0.0008, grad_fn=<MeanBackward0>), 'cls': tensor(0.2300, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.1793, grad_fn=<AddBackward0>), 'ciou': tensor(1.9892, grad_fn=<MeanBackward0>), 'obj': tensor(0.0006, grad_fn=<MeanBackward0>), 'cls': tensor(0.1552, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009915301796042076\n",
      "[9/100] training start\n",
      "loss value: {'total': tensor(0.2111, grad_fn=<AddBackward0>), 'ciou': tensor(1.9312, grad_fn=<MeanBackward0>), 'obj': tensor(0.0006, grad_fn=<MeanBackward0>), 'cls': tensor(0.2241, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.3356, grad_fn=<AddBackward0>), 'ciou': tensor(3.8972, grad_fn=<MeanBackward0>), 'obj': tensor(0.0008, grad_fn=<MeanBackward0>), 'cls': tensor(0.2750, grad_fn=<MeanBackward0>)}\n",
      "loss value: {'total': tensor(0.2172, grad_fn=<AddBackward0>), 'ciou': tensor(1.9336, grad_fn=<MeanBackward0>), 'obj': tensor(0.0012, grad_fn=<MeanBackward0>), 'cls': tensor(0.2314, grad_fn=<MeanBackward0>)}\n",
      "learning rate: 0.009884847360911168\n",
      "[10/100] training start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, training_config\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m     gt_datas \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = DetectionLoss(num_classes=len(dataset_config.classes),\n",
    "                     weight_lst=[OptimizerConfig.iou_normalizer,\n",
    "                                 OptimizerConfig.obj_normalizer,\n",
    "                                 OptimizerConfig.cls_normalizer]) \n",
    "\n",
    "learning_rate = []                     \n",
    "print(f\"start learning rate: {OptimizerConfig.lr0}\")          \n",
    "\n",
    "for epoch in range(training_config.epochs):\n",
    "    prefix=\"[{}/{}]\".format(epoch, training_config.epochs)\n",
    "    print(f\"{prefix} training start\")\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        gt_datas = data\n",
    "        output = model(data['image'])\n",
    "        result = torch.cat((output[0],output[1],output[2]),dim=1)\n",
    "        gt_bboxes = gt_datas['bboxes']\n",
    "        gt_class_labels = gt_datas['class_labels']\n",
    "        gt_class_labels = gt_class_labels.view(gt_class_labels.shape[0],\n",
    "                                               gt_class_labels.shape[1],\n",
    "                                               1)\n",
    "        gt = torch.cat((gt_bboxes,gt_class_labels),dim=2)  \n",
    "        loss_value = loss(result, gt)\n",
    "        loss_value['total'].backward()\n",
    "        optimizer.step()  \n",
    "        print(f\"loss value: {loss_value}\")\n",
    "        \n",
    "        #for test\n",
    "        if i == 2:\n",
    "            break\n",
    "\n",
    "    \n",
    "\n",
    "    if training_config.lr_sheduler:\n",
    "        yolo_scheduler.step()\n",
    "        temp_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rate.append(temp_lr)\n",
    "        print(f\"learning rate: {temp_lr}\")\n",
    "\n",
    "    '''\n",
    "    if epoch % training_config.save_period == 0:\n",
    "        torch.save(model.state_dict(), training_config.save_dir + f\"yolo_epoch_{epoch}.pth\")\n",
    "        print(f\"model saved at epoch {epoch}\")\n",
    "    '''\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
