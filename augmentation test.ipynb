{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import backbone\n",
    "import anchor\n",
    "import importlib\n",
    "import Custom_dataset\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from CustomAugment import Cutmix\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set size: 1084, test_set size : 272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(image_test)):\\n    try:\\n        data = image_test[i]\\n        img_shape = data[\\'image\\'].shape\\n        bboxes = data[\\'bboxes\\']\\n        label_count = len(bboxes)\\n        \\n        # bbox 확인\\n        for j, bbox in enumerate(bboxes):\\n            cx, cy, w, h = bbox\\n            x1 = cx - w / 2\\n            y1 = cy - h / 2\\n            x2 = cx + w / 2\\n            y2 = cy + h / 2\\n\\n            if not (0 <= x1 <= 1 and 0 <= y1 <= 1 and 0 <= x2 <= 1 and 0 <= y2 <= 1):\\n                raise ValueError(f\"bbox {j} out of bounds: {bbox}\")\\n\\n            if w <= 0 or h <= 0:\\n                raise ValueError(f\"bbox {j} has non-positive size: {bbox}\")\\n\\n        print(f\"[{i}] ✅ success: {img_shape}, {label_count} boxes\")\\n\\n    except Exception as e:\\n        print(f\"[{i}] ❌ failed with error: {e}\")\\n        break  # 또는 continue\\n        '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(Custom_dataset)\n",
    "\n",
    "image_dir = \"dataset\\\\image\\\\\"\n",
    "label_dir = \"dataset\\\\label\\\\\"\n",
    "classes = {0:'background',1:'NG',2:'OK'}\n",
    "\n",
    "image_test =Custom_dataset.ListDataset(image_dir,label_dir,classes,transform=False)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.RandomSizedBBoxSafeCrop(width=450,height=450,erosion_rate=0.8),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'], # Specify label argument name(s)\n",
    "                            ))\n",
    "\n",
    "final_transform = A.Compose([\n",
    "    A.AdditiveNoise(noise_type=\"gaussian\",\n",
    "                    spatial_mode=\"constant\",\n",
    "                    noise_params={\"mean_range\": (0.0, 0.0), \"std_range\": (0.05, 0.15)}),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),\n",
    "    A.Affine(translate_percent={'x': (-0.2, 0.2), 'y': (-0.2, 0.2)},  # x축 10~20%, y축 -20~20% 랜덤 이동\n",
    "             p=0.3),\n",
    "    A.Affine(rotate = (-20,20), p = 0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'], # Specify label argument name(s)\n",
    "                           ))\n",
    "\n",
    "aug_para ={\"alpha\":0.7,\"lambda\":0.7,\"prob\":0.5}\n",
    "\n",
    "\n",
    "image_test.add_agumentation(train_transform,aug_para,final_transform)\n",
    "\n",
    "set_size = len(image_test)\n",
    "train_dataset_size = int(0.8*set_size)\n",
    "test_dataset_size = set_size-train_dataset_size\n",
    "\n",
    "train_indces, valid_indces = torch.utils.data.random_split(range(set_size), [train_dataset_size, test_dataset_size])\n",
    "print(\"set size: {0}, test_set size : {1}\".format(train_dataset_size,test_dataset_size))\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(image_test, train_indces)\n",
    "valid_dataset = torch.utils.data.Subset(image_test, train_indces)\n",
    "# This problem is occured in Dater type interupt between array and tensor\n",
    "\n",
    "batch_size = 5\n",
    "num_workers = 1\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               collate_fn = image_test.collate_fn)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               collate_fn = image_test.collate_fn)\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(len(image_test)):\n",
    "    try:\n",
    "        data = image_test[i]\n",
    "        img_shape = data['image'].shape\n",
    "        bboxes = data['bboxes']\n",
    "        label_count = len(bboxes)\n",
    "        \n",
    "        # bbox 확인\n",
    "        for j, bbox in enumerate(bboxes):\n",
    "            cx, cy, w, h = bbox\n",
    "            x1 = cx - w / 2\n",
    "            y1 = cy - h / 2\n",
    "            x2 = cx + w / 2\n",
    "            y2 = cy + h / 2\n",
    "\n",
    "            if not (0 <= x1 <= 1 and 0 <= y1 <= 1 and 0 <= x2 <= 1 and 0 <= y2 <= 1):\n",
    "                raise ValueError(f\"bbox {j} out of bounds: {bbox}\")\n",
    "\n",
    "            if w <= 0 or h <= 0:\n",
    "                raise ValueError(f\"bbox {j} has non-positive size: {bbox}\")\n",
    "\n",
    "        print(f\"[{i}] ✅ success: {img_shape}, {label_count} boxes\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{i}] ❌ failed with error: {e}\")\n",
    "        break  # 또는 continue\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(anchor)\n",
    "\n",
    "anchoring = anchor.DataEncoder((450,450),classes=[0,1])\n",
    "\n",
    "\n",
    "test_out,test_cls = anchoring.encoder(gt_boxes,gt_classes)\n",
    "\n",
    "print(test_cls)\n",
    "\n",
    "unique, counts = test_cls.unique(return_counts=True)\n",
    "for u, c in zip(unique, counts):  \n",
    "    print(f\"클래스 {int(u)}: {int(c)}개\")\n",
    "\n",
    "\n",
    "print(13*13*3,26*26*3,52*52*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(custom_dataset)\n",
    "\n",
    "image_dir = \"dataset\\\\image\\\\\"\n",
    "label_dir = \"dataset\\\\label\\\\\"\n",
    "classes = {0:'background',1:'NG',2:'OK'}\n",
    "\n",
    "image_test =custom_dataset.ListDataset(image_dir,label_dir,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "image,boxes, label=image_test[0]\n",
    "print(len(image_test))\n",
    "print(label)\n",
    "print(image.shape)\n",
    "print(boxes)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_lst = ['NG','OK']\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.RandomSizedBBoxSafeCrop(width=450,height=450,erosion_rate=0.8),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'] # Specify label argument name(s)\n",
    "                           ))\n",
    "\n",
    "augmented = train_transform(image=image,bboxes=boxes,class_labels=label)\n",
    "\n",
    "img = augmented['image']\n",
    "result_label = augmented['class_labels']\n",
    "\n",
    "print(img.dtype)\n",
    "for i, box in enumerate(augmented['bboxes']):\n",
    "    x_center, y_center, w, h = box\n",
    "    x1 = int((x_center - w/2) * 450)\n",
    "    y1 = int((y_center - h/2) * 450)\n",
    "    x2 = int((x_center + w/2) * 450)\n",
    "    y2 = int((y_center + h/2) * 450)\n",
    "    if result_label[i] == 1:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "plt.imshow(img)\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class MixUp:\n",
    "    def __init__(self, alpha=0.7, prob=0.5):\n",
    "        self.alpha = alpha\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, datsset1, dataset2):\n",
    "        img1 = np.array(datsset1['image']) / 255\n",
    "        img2 = np.array(dataset2['image']) / 255\n",
    "        mixed_img = (self.alpha * img1 + (1-self.alpha) * img2)\n",
    "        mixed_boxes = datsset1['bboxes'] + dataset2['bboxes'] \n",
    "        mixed_labels = datsset1['class_labels'] + dataset2['class_labels']\n",
    "\n",
    "        return mixed_img, mixed_boxes, mixed_labels\n",
    "\n",
    "image_A,boxes_A,label_A=image_test[0]\n",
    "image_B,boxes_B,label_B=image_test[100]\n",
    "augmentedA = train_transform(image=image_A,bboxes=boxes_A,class_labels=label_A)\n",
    "augmentedB = train_transform(image=image_B,bboxes=boxes_B,class_labels=label_B)\n",
    "\n",
    "aug2 = MixUp(alpha=0.5, prob=1)\n",
    "m_1,m_2,m_3 = aug2(augmentedA,augmentedB)\n",
    "\n",
    "img = m_1\n",
    "result_label = m_3\n",
    "\n",
    "for i, box in enumerate(m_2):\n",
    "    x_center, y_center, w, h = box\n",
    "    x1 = int((x_center - w/2) * 450)\n",
    "    y1 = int((y_center - h/2) * 450)\n",
    "    x2 = int((x_center + w/2) * 450)\n",
    "    y2 = int((y_center + h/2) * 450)\n",
    "    if result_label[i] == 1:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "plt.imshow(img)\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_transform(transform, dataset, indices):\n",
    "    \"\"\"\n",
    "    transform: Albumentations transform 객체 (예: train_transform)\n",
    "    dataset: [(image, boxes, labels), ...] 형태의 리스트 or 커스텀 Dataset\n",
    "    indices: 4개의 인덱스를 가진 리스트 (예: [0, 100, 10, 75])\n",
    "\n",
    "    return: list of transformed outputs [(image, boxes, labels), ...]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for idx in indices:\n",
    "        image, boxes, labels = dataset[idx]\n",
    "        augmented = transform(image=image, bboxes=boxes, class_labels=labels)\n",
    "        results.append((augmented['image'], augmented['bboxes'], augmented['class_labels']))\n",
    "    return results\n",
    "\n",
    "augmented_outputs = apply_transform(train_transform,image_test,[10,20,30,40])\n",
    "images = [out[0] for out in augmented_outputs]\n",
    "bboxes = [out[1] for out in augmented_outputs]\n",
    "labels = [out[2] for out in augmented_outputs]\n",
    "\n",
    "Mosic_test = custom_dataset.SimpleMosaic(225,True)\n",
    "m_1,m_2,m_3 = Mosic_test(image=images, bboxes=bboxes, class_labels=labels)\n",
    "\n",
    "img = m_1\n",
    "result_label = m_3\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "for i, box in enumerate(m_2):\n",
    "    x_center, y_center, w, h = box\n",
    "    x1 = int((x_center - w/2) * 450)\n",
    "    y1 = int((y_center - h/2) * 450)\n",
    "    x2 = int((x_center + w/2) * 450)\n",
    "    y2 = int((y_center + h/2) * 450)\n",
    "    if result_label[i] == 1:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "plt.imshow(img)\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "importlib.reload(custom_dataset)\n",
    "\n",
    "image_A,boxes_A,label_A=image_test[0]\n",
    "image_B,boxes_B,label_B=image_test[99]\n",
    "augmentedA = train_transform(image=image_A,bboxes=boxes_A,class_labels=label_A)\n",
    "augmentedB = train_transform(image=image_B,bboxes=boxes_B,class_labels=label_B)\n",
    "\n",
    "aug2 = custom_dataset.Cutmix(lamda=0.5, prob=1)\n",
    "m_1,m_2,m_3 = aug2(augmentedA,augmentedB)\n",
    "\n",
    "img = m_1\n",
    "result_label = m_3\n",
    "\n",
    "for i, box in enumerate(m_2):\n",
    "    x_center, y_center, w, h = box\n",
    "    x1 = int((x_center - w/2) * 450)\n",
    "    y1 = int((y_center - h/2) * 450)\n",
    "    x2 = int((x_center + w/2) * 450)\n",
    "    y2 = int((y_center + h/2) * 450)\n",
    "    if result_label[i] == 1:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "plt.imshow(img)\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
