{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import backbone\n",
    "import anchor\n",
    "import importlib\n",
    "import Custom_dataset\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch import optim\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "from CustomAugment import Cutmix\n",
    "from configuration import dataset_config\n",
    "from configuration import dataloader_config\n",
    "from configuration import OptimizerConfig\n",
    "from configuration import augmentation_config\n",
    "from configuration import training_config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set size: 1084, test_set size : 272\n",
      "batch shape: torch.Size([32, 3, 448, 448])\n",
      "backbone output : [torch.Size([32, 32, 448, 448]), torch.Size([32, 64, 224, 224]), torch.Size([32, 128, 112, 112]), torch.Size([32, 256, 56, 56]), torch.Size([32, 512, 28, 28]), torch.Size([32, 1024, 14, 14])]\n",
      "P_large_output : torch.Size([32, 512, 14, 14])\n",
      "route_3 interpolation  : torch.Size([32, 256, 28, 28])\n",
      "before route_2  : torch.Size([32, 512, 28, 28])\n",
      "after route_2  : torch.Size([32, 256, 28, 28])\n",
      "torch.Size([32, 256, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i, data in enumerate(train_dataset):\\n    print(f\"\\nüåÄ step : {i}\")\\n    print(f\"bboxes shape: {data[\\'bboxes\\'].shape}\")\\n    print(f\"class_labels shape: {data[\\'class_labels\\'].shape}\")\\n    \\n    result_bboxes, result_labels = image_test.encoder.encoder(data[\\'bboxes\\'], data[\\'class_labels\\'])\\n    \\n    print(f\"result_bboxes shape: {result_bboxes.shape}\")\\n    print(f\"result_labels shape: {result_labels.shape}\")\\n    \\n    print(f\"ignore label: {(result_labels == -1).sum().item()}\")\\n    print(f\"background label: {(result_labels == 0).sum().item()}\") \\n    print(f\"0 label: {(result_labels == 1).sum().item()}\") \\n    print(f\"1 label: {(result_labels == 2).sum().item()}\") \\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated() \n",
    "\n",
    "\n",
    "image_dir = dataset_config.image_dir\n",
    "label_dir = dataset_config.label_dir\n",
    "classes = dataset_config.classes\n",
    "img_size = dataset_config.image_size\n",
    "\n",
    "image_test =Custom_dataset.ListDataset(image_dir,\n",
    "                                       label_dir,\n",
    "                                       classes,\n",
    "                                       transform=augmentation_config.transform)\n",
    "\n",
    "# RabdinSized BBox Safe Crop has box bigger than 1% of image size\n",
    "train_transform = A.Compose([\n",
    "    A.RandomSizedBBoxSafeCrop(width=img_size,height=img_size,erosion_rate=0.8),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'], # Specify label argument name(s)\n",
    "                            ))\n",
    "\n",
    "final_transform = A.Compose([\n",
    "    A.AdditiveNoise(noise_type=\"gaussian\",\n",
    "                    spatial_mode=\"constant\",\n",
    "                    noise_params={\"mean_range\": (0.0, 0.0), \"std_range\": (0.05, 0.15)}),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),\n",
    "    A.Affine(translate_percent={'x': (-0.2, 0.2), 'y': (-0.2, 0.2)},  # xÏ∂ï 10~20%, yÏ∂ï -20~20% ÎûúÎç§ Ïù¥Îèô\n",
    "             p=0.3),\n",
    "    A.Affine(rotate = (-20,20), p = 0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='yolo', # Specify input format\n",
    "                           label_fields=['class_labels'], # Specify label argument name(s)\n",
    "                           ))\n",
    "\n",
    "aug_para ={\"alpha\":augmentation_config.alpha,\n",
    "           \"lambda\":augmentation_config.lamda,\n",
    "           \"prob\":augmentation_config.prob}\n",
    "\n",
    "\n",
    "image_test.add_agumentation(train_transform,aug_para,final_transform)\n",
    "\n",
    "set_size = len(image_test)\n",
    "train_dataset_size = int(0.8*set_size)\n",
    "test_dataset_size = set_size-train_dataset_size\n",
    "\n",
    "train_indces, valid_indces = torch.utils.data.random_split(range(set_size), [train_dataset_size, test_dataset_size])\n",
    "print(\"set size: {0}, test_set size : {1}\".format(train_dataset_size,test_dataset_size))\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(image_test, train_indces)\n",
    "valid_dataset = torch.utils.data.Subset(image_test, train_indces)\n",
    "# This problem is occured in Dater type interupt between array and tensor\n",
    "\n",
    "batch_size = dataloader_config.batch_size\n",
    "num_workers = dataloader_config.num_workers\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=dataloader_config.batch_size,\n",
    "                                               num_workers=dataloader_config.num_workers,\n",
    "                                               shuffle = dataloader_config.shuffle,\n",
    "                                               collate_fn = image_test.collate_fn)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=dataloader_config.batch_size,\n",
    "                                               num_workers=dataloader_config.num_workers,\n",
    "                                               collate_fn = image_test.collate_fn)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "model = backbone.YoloV4Model(num_classes=len(dataset_config.classes),\n",
    "                             to_vector = True)\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(training_config.epochs):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        print(f\"batch shape: {data['image'].shape}\")\n",
    "        output = model(data['image'])\n",
    "        break\n",
    "    break\n",
    "\n",
    "'''\n",
    "for i, data in enumerate(train_dataset):\n",
    "    print(f\"\\nüåÄ step : {i}\")\n",
    "    print(f\"bboxes shape: {data['bboxes'].shape}\")\n",
    "    print(f\"class_labels shape: {data['class_labels'].shape}\")\n",
    "    \n",
    "    result_bboxes, result_labels = image_test.encoder.encoder(data['bboxes'], data['class_labels'])\n",
    "    \n",
    "    print(f\"result_bboxes shape: {result_bboxes.shape}\")\n",
    "    print(f\"result_labels shape: {result_labels.shape}\")\n",
    "    \n",
    "    print(f\"ignore label: {(result_labels == -1).sum().item()}\")\n",
    "    print(f\"background label: {(result_labels == 0).sum().item()}\") \n",
    "    print(f\"0 label: {(result_labels == 1).sum().item()}\") \n",
    "    print(f\"1 label: {(result_labels == 2).sum().item()}\") \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 588, 7])\n",
      "torch.Size([32, 2352, 7])\n",
      "torch.Size([32, 9408, 7])\n",
      "torch.Size([32, 12348, 7])\n"
     ]
    }
   ],
   "source": [
    "print(output[0].shape)\n",
    "print(output[1].shape)\n",
    "print(output[2].shape)\n",
    "result = torch.cat((output[0],output[1],output[2]),dim=1)\n",
    "print(result.shape)\n",
    "#ÎÇ¥Ïùº ÏïÑÏπ®Ïóê ÏùºÏñ¥ÎÇòÏÑú ÌôïÏù∏Ìï¥Î¥êÏïºÎê†Í±∞ -> result ÌÖêÏÑúÌÅ¨Í∏∞ ÌôïÏù∏Ïù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define total batch size \n",
    "total_batch_size = math.ceil(train_dataset_size / dataloader_config.batch_size)  # total batch size for all GPUs, accumulate, and gradient steps\n",
    "\n",
    "nbs = 64  # nominal batch size\n",
    "accumulate = max(round(nbs / total_batch_size), 1)  # accumulate loss before optimizing\n",
    "modified_weight_decay= OptimizerConfig.weight_decay * total_batch_size * accumulate / nbs  # scale weight_decay\n",
    "optimizer = optim.Adam(params = model.parameters(),\n",
    "                       lr=OptimizerConfig.lr0, \n",
    "                       weight_decay=modified_weight_decay, #L2 regularization\n",
    "                       betas=(0.9,0.999) )  # adjust beta1 to momentum\n",
    "\n",
    "# Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
    "# https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR\n",
    "warmup_end_lr =  (1-OptimizerConfig.lrf)/2+OptimizerConfig.lrf  # warmup end learning rate\n",
    "warmup_scheduler = lr_scheduler.LinearLR(optimizer, \n",
    "                                         start_factor=OptimizerConfig.lr0, \n",
    "                                         end_factor= warmup_end_lr,\n",
    "                                         total_iters=training_config.warmup_epochs)\n",
    "\n",
    "# Cosine decay after warmup\n",
    "epochs_cosine = training_config.epochs - training_config.warmup_epochs\n",
    "lf = lambda x: ((1 + math.cos(x * math.pi / epochs_cosine)) / 2) * (1 - OptimizerConfig.lrf) + OptimizerConfig.lrf  # cosine\n",
    "cosine_scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
